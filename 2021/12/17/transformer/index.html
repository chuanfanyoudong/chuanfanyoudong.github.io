<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Transformer解释 | 杂记</title>
  <meta name="keywords" content=" 自然语言处理 ">
  <meta name="description" content="Transformer解释 | 杂记">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="许久没有登录，发现git用不了了，原来现在不支持用户名密码登录，支持的是用户名token登录，也就是密码换成token">
<meta property="og:type" content="article">
<meta property="og:title" content="git&#x2F;基础配置">
<meta property="og:url" content="http:&#x2F;&#x2F;blog.chuanfanyoudong.com&#x2F;2022&#x2F;03&#x2F;16&#x2F;git&#x2F;%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE&#x2F;index.html">
<meta property="og:site_name" content="杂记">
<meta property="og:description" content="许久没有登录，发现git用不了了，原来现在不支持用户名密码登录，支持的是用户名token登录，也就是密码换成token">
<meta property="article:published_time" content="2022-03-16T00:43:08.279Z">
<meta property="article:modified_time" content="2022-03-16T01:04:06.692Z">
<meta property="article:author" content="船帆有洞">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.0.1" ></script>

<meta name="generator" content="Hexo 4.1.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="true">
  <input class="theme_blog_path" value="">
</div>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>船帆有洞</span>
</div>

<div class="icon">
    
        
        <a title="rss" href="/atom.xml" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-rss"></use>
                </svg>
            
        </a>
        
    
        
        <a title="github" href="https://github.com/chuanfanyoudong" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
        <a title="email" href="mailto:jiang_zhenkang@163.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"></use>
                </svg>
            
        </a>
        
    
        
        <a title="qq" href="http://wpa.qq.com/msgrd?v=3&uin=756464383&site=qq&menu=yes" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-qq"></use>
                </svg>
            
        </a>
        
    
        
        <a title="kugou" href="https://www.kugou.com/" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-kugou"></use>
                </svg>
            
        </a>
        
    
        
    
</div>




<ul>
    <li><div class="all active">全部文章<small>(13)</small></div></li>
    
        
            
            <li><div data-rel="算法">算法<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="技术">技术<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="生活">生活<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="python">python<small>(1)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="博客">博客<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="随笔">随笔<small>(1)</small></div>
                
            </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div><a class="about  hasFriend  site_url"  href="/about">关于</a><a style="width: 50%"  class="friends">友链</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="13">
<input type="hidden" id="yelog_site_word_count" value="7.8k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://blog.chuanfanyoudong.com">杂记</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="Search..." autocomplete="off"id="local-search-input" >
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a class="color3">生活</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">自然语言处理</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">文本分类</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">算法</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">python</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">hexo</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">随笔</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <nav id="title-list-nav">
        
        <a  class=""
           href="/2020/02/02/HMM/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="HMM">HMM</span>
            <span class="post-date" title="2020-02-02 08:48:02">2020/02/02</span>
        </a>
        
        <a  class="算法 "
           href="/2019/12/17/TextCNN%E5%9B%BE%E7%A4%BA/"
           data-tag="自然语言处理,文本分类"
           data-author="" >
            <span class="post-title" title="TextCNN图示">TextCNN图示</span>
            <span class="post-date" title="2019-12-17 00:00:00">2019/12/17</span>
        </a>
        
        <a  class="技术 "
           href="/2020/01/31/TF-IDF/"
           data-tag="自然语言处理,算法"
           data-author="" >
            <span class="post-title" title="TF-IDF">TF-IDF</span>
            <span class="post-date" title="2020-01-31 00:00:00">2020/01/31</span>
        </a>
        
        <a  class=""
           href="/2020/02/02/hello-world/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Hello World">Hello World</span>
            <span class="post-date" title="2020-02-02 08:48:02">2020/02/02</span>
        </a>
        
        <a  class=""
           href="/2020/02/02/%E5%85%AC%E5%8A%A1%E5%91%98%E9%9D%A2%E8%AF%951/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="公务员面试1">公务员面试1</span>
            <span class="post-date" title="2020-02-02 08:48:02">2020/02/02</span>
        </a>
        
        <a  class="生活 "
           href="/2020/01/28/%E9%80%89%E6%89%8B%E6%9C%BA/"
           data-tag="生活"
           data-author="" >
            <span class="post-title" title="选手机">选手机</span>
            <span class="post-date" title="2020-01-28 00:00:00">2020/01/28</span>
        </a>
        
        <a  class="python "
           href="/2020/02/29/python/%E5%AE%89%E8%A3%85anaconda%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/"
           data-tag="python"
           data-author="" >
            <span class="post-title" title="anaconda安装及相关配置">anaconda安装及相关配置</span>
            <span class="post-date" title="2020-02-29 00:00:00">2020/02/29</span>
        </a>
        
        <a  class="博客 "
           href="/2020/02/02/%E5%8D%9A%E5%AE%A2/hexo%E5%8D%9A%E5%AE%A2markdown%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%88%B0github%E5%88%86%E6%94%AF/"
           data-tag="hexo"
           data-author="" >
            <span class="post-title" title="hexo博客markdown文件上传到github分支">hexo博客markdown文件上传到github分支</span>
            <span class="post-date" title="2020-02-02 00:00:00">2020/02/02</span>
        </a>
        
        <a  class="博客 "
           href="/2020/02/05/%E5%8D%9A%E5%AE%A2/hexo%E5%8D%9A%E5%AE%A2%E5%AF%BC%E5%85%A5%E5%9B%BE%E7%89%87/"
           data-tag="hexo"
           data-author="" >
            <span class="post-title" title="hexo博客导入图片">hexo博客导入图片</span>
            <span class="post-date" title="2020-02-05 00:00:00">2020/02/05</span>
        </a>
        
        <a  class="随笔 "
           href="/2020/04/10/%E9%9A%8F%E7%AC%94/%E6%BF%80%E6%B4%BBwindows/"
           data-tag="随笔"
           data-author="" >
            <span class="post-title" title="激活windows office 2010">激活windows office 2010</span>
            <span class="post-date" title="2020-04-10 22:43:36">2020/04/10</span>
        </a>
        
        <a  class=""
           href="/2022/03/16/git/%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="git/基础配置">git/基础配置</span>
            <span class="post-date" title="2022-03-16 08:43:08">2022/03/16</span>
        </a>
        
        <a  class="算法 "
           href="/2021/12/17/transformer/"
           data-tag="自然语言处理"
           data-author="" >
            <span class="post-title" title="Transformer解释">Transformer解释</span>
            <span class="post-date" title="2021-12-17 00:00:00">2021/12/17</span>
        </a>
        
        <a  class=""
           href="/2022/03/17/TextRank/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="TextRank">TextRank</span>
            <span class="post-date" title="2022-03-17 09:35:30">2022/03/17</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-transformer" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">Transformer解释</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
                <a  data-rel="算法">算法</a>
            
        </span>
        
        
        <span class="tag">
            
            <a class="color2">自然语言处理</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2022-03-17 08:27:22'>2021-12-17 00:00</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:1.5k</span>
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#概述"><span class="toc-text">概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#用向量描述一下"><span class="toc-text">用向量描述一下</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#encoding过程"><span class="toc-text">encoding过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#selof-attention"><span class="toc-text">selof_attention</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#self-attention的细节"><span class="toc-text">self_attention的细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#self-attention的矩阵算法"><span class="toc-text">self_attention的矩阵算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多头注意力"><span class="toc-text">多头注意力</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#编码序列的位置信息"><span class="toc-text">编码序列的位置信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#残差信息"><span class="toc-text">残差信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#两层的结构如下："><span class="toc-text">两层的结构如下：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#decoder部分"><span class="toc-text">decoder部分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#最终的全连接与softmax"><span class="toc-text">最终的全连接与softmax</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练过程的复盘"><span class="toc-text">训练过程的复盘</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#损失函数——loss-function"><span class="toc-text">损失函数——loss function</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#预测的时候用到了-beam-search方法"><span class="toc-text">预测的时候用到了 beam search方法</span></a></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>[toc]</p>
<ul>
<li>本文基本翻译自：<a href="http://jalammar.github.io/illustrated-transformer" target="_blank" rel="noopener">http://jalammar.github.io/illustrated-transformer</a></li>
<li><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">http://jalammar.github.io/illustrated-transformer/</a></li>
<li>论文地址：<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">https://arxiv.org/abs/1706.03762</a></li>
</ul>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>encoder和decode都包括六层，每层相同，每层之间也不共享权重</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/9q7tw5tixorn3rm13m4q6u7t/image_1d4pqb2rtjes1abv1qjaakq1s8n9.png" alt="image_1d4pqb2rtjes1abv1qjaakq1s8n9.png-105kB"></p>
<ul>
<li>每一层encoder的结构如下</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/s6tfvmopezmjub33wgcr4b61/image_1d4pqc2471tccakd6h47pd1ek7m.png" alt="image_1d4pqc2471tccakd6h47pd1ek7m.png-26kB"></p>
<ul>
<li><p>self_attention:帮助encoder在解码一个字的时候关注到句子的其余词语</p>
</li>
<li><p>self_attention的输出会送到feed_forward网络，</p>
</li>
<li><p>每一层decoder的结构如下</p>
</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/dhld92snu1ehr2g706wa1dwi/image_1d4pqk58d27o1d3fakn1i451maa13.png" alt="image_1d4pqk58d27o1d3fakn1i451maa13.png-32.7kB"></p>
<ul>
<li>decoder层有encoder层的两层结构（self_attention和feed_foreard)并且在两层中间有一个encoder-decoder-attention层,这一层能够帮助关注输入和输出的注意力机制</li>
</ul>
<h2 id="用向量描述一下"><a href="#用向量描述一下" class="headerlink" title="用向量描述一下"></a>用向量描述一下</h2><ul>
<li>首先我们把输入的所有词转换成词向量，如下图示：</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/p2q828vx0wauoixlwnp5y16j/image_1d4pqrqj56qiesocmj1nrsgth20.png" alt="image_1d4pqrqj56qiesocmj1nrsgth20.png-12.8kB"></p>
<ul>
<li><p>只有最开始输入的encoder的维度是词向量的维度，剩下的所有的encoder的维度都是隐藏层维度，在这里可以是512（这个维度是可以人为设定的）</p>
</li>
<li><p>下面进入encoder环节</p>
</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/izr55upv6tosswq4sqf0ngf4/image_1d4pr1cah15pq8lgc9rkn4ifh2d.png" alt="image_1d4pr1cah15pq8lgc9rkn4ifh2d.png-54.5kB"></p>
<ul>
<li>self-attention不可以并行，但是feed-forward可以并行</li>
</ul>
<h2 id="encoding过程"><a href="#encoding过程" class="headerlink" title="encoding过程"></a>encoding过程</h2><ul>
<li>图示：<br><img src="http://static.zybuluo.com/chuanfanyoudong/xug97j0rk49ohz9k3um8q0g8/image_1d4prae4v1rcu1jqo1bss17411ddt2q.png" alt="image_1d4prae4v1rcu1jqo1bss17411ddt2q.png-74.9kB"></li>
</ul>
<h3 id="selof-attention"><a href="#selof-attention" class="headerlink" title="selof_attention"></a>selof_attention</h3><ul>
<li>不要被sdelf_attention这个概念唬住，其实在这边论文出来之前，我们就已经知道self_attention啦</li>
<li>我们打算翻译下面这句话：<br>  <img src="http://static.zybuluo.com/chuanfanyoudong/2r73r3zsb9c12kpjusif2zlk/image_1d4pre3i69bhku24t91ft815g537.png" alt="image_1d4pre3i69bhku24t91ft815g537.png-4kB"></li>
<li>当我们encoder“it”这个词的时候，self_attention可以让“it”和“animal”这个词关联起来</li>
<li>对每个词都这样就会使得encoder效果更好</li>
<li>这里self_attention是用来和RNN做对应的，都可以在处理这个词的时候将其他词的向量融合进去，下面图示<br><img src="http://static.zybuluo.com/chuanfanyoudong/t3uimub3nfvk1paovimcjc41/image_1d4prqrb12k2ahh12fhvcnpmk3k.png" alt="image_1d4prqrb12k2ahh12fhvcnpmk3k.png-46.3kB"></li>
<li>一个测试transfor的脚本链接：<a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" target="_blank" rel="noopener">https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb</a></li>
</ul>
<h3 id="self-attention的细节"><a href="#self-attention的细节" class="headerlink" title="self_attention的细节"></a>self_attention的细节</h3><ul>
<li><p>下图示：<br><img src="http://static.zybuluo.com/chuanfanyoudong/emtf9m6yhassaygunv0soc67/image_1d4psl2c71go8t1mbqa1be415d741.png" alt="image_1d4psl2c71go8t1mbqa1be415d741.png-44.5kB"></p>
</li>
<li><p>对每一个输入的单词向量， 会有一个query向量，一个key向量，一个value向量</p>
</li>
<li><p>这三个向量的来历：在我们进行到“thinking”这个词的时候，我们会计算“thinking”这个词需要的每个词的权重， 就是encoder “thinging”这个词的时候，我们会对其他词的关注程度，这里的计算方法，就是“thinging”这个词的q与所有词的k进行点乘，作为权重得分。如下图所示：</p>
</li>
<li><p><img src="http://static.zybuluo.com/chuanfanyoudong/my0nmxu1ndg0900sl7w1tjyt/image_1d4pst1p2161k1hj887t14abftq4e.png" alt="image_1d4pst1p2161k1hj887t14abftq4e.png-29kB"></p>
</li>
<li><p>下一步就是除以key向量的维度的开方，比如key的维度是64，那么要除以64的开方，也就是8，最后进行softmax，得到0.88和0.12，这样做是为了有更平缓的梯度。</p>
</li>
<li><p>这一步将决定没个词的权重，诚然本身这个词（“thinking”）的权重会最大，但是其余此有时候也会很有用<br><img src="http://static.zybuluo.com/chuanfanyoudong/ck9qky0epb5dc67bksh1p3df/image_1d4pt3gru858tpe3q18bi16k44r.png" alt="image_1d4pt3gru858tpe3q18bi16k44r.png-48.2kB"></p>
</li>
<li><p>下一步就是将上一步softmax的得分与value向量相乘，求和输出，如下图示：<br><img src="http://static.zybuluo.com/chuanfanyoudong/a98fb6i8du6pef8da63fj51t/image_1d4ptgg1mibs1vlsdrc1p7b1bhp71.png" alt="image_1d4ptgg1mibs1vlsdrc1p7b1bhp71.png-57.9kB"></p>
</li>
</ul>
<h3 id="self-attention的矩阵算法"><a href="#self-attention的矩阵算法" class="headerlink" title="self_attention的矩阵算法"></a>self_attention的矩阵算法</h3><ul>
<li>query,key,value怎么来的？也是算出来的看图：</li>
<li><img src="http://static.zybuluo.com/chuanfanyoudong/ytraxnvimest7p5kmglhek3i/image_1d4ptoq651bdkaqp9g814qt1ijb7e.png" alt="image_1d4ptoq651bdkaqp9g814qt1ijb7e.png-25kB"></li>
<li>这里假设只有两个词，词向量维度是4，所以X的维度是2<em>4，所以乘上WQ（4</em>3,3是query的维度）就求出query矩阵，同理：可以求出key矩阵，value矩阵。</li>
<li><img src="http://static.zybuluo.com/chuanfanyoudong/34es21yw8swxcpda5i6x57a1/image_1d4ptv8521e0sk1c1svs6m4mqn7r.png" alt="image_1d4ptv8521e0sk1c1svs6m4mqn7r.png-20.4kB"></li>
<li>解释一下上图矩阵的求法，Q的每一行代表每一个词，与K的每一列相乘，代表当前Q对k的当前列的权重，所以乘出来是一个2*2</li>
<li>其中点第一行第一列的点代表第一个词的query与第一个词的key的点乘</li>
<li>第一行第二列代表第一个词的query与第二个词的key的点乘</li>
<li>第二行第一列代表第二个词的query与第一个词的key的点乘</li>
<li>第二行第二列代表第二个词的query与第二个词的key的点乘</li>
<li>然后对每一行进行softmax，就得到了权重，然后与value矩阵相乘，就得到了最终的结果</li>
<li>2*2矩阵的第一行与value矩阵的第一列相乘，代表着第一个词的输出value向量在第一个维度上的加权输出。其余类似</li>
</ul>
<h3 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h3><ul>
<li><p>虽然self_attention使得输出结果有了其他词的融合，但是主要还是这个词本身。</p>
</li>
<li><p>给了输出更大的表示向量空间</p>
</li>
<li><p>如图所示为：图中为有两个头</p>
</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/fn4wfv5bsanp3e9wmu5tz7cl/image_1d4pun7oc1cck1tl3qi78n1imb8d.png" alt="image_1d4pun7oc1cck1tl3qi78n1imb8d.png-58.2kB"></p>
<ul>
<li><p>每个头中的三个权重矩阵互不干涉，那么最终我们会得到8个（论文中有8个头数量）输出矩阵。<br><img src="http://static.zybuluo.com/chuanfanyoudong/9qm0ve87n68k85m43dxyahih/image_1d4puqgki1dlh68e1j611st48q.png" alt="image_1d4puqgki1dlh68e1j611st48q.png-52.2kB"></p>
</li>
<li><p>然后我们把八个矩阵拼起来再和另一个矩阵相乘，得到最终输出：</p>
</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/b3z6otq34mcfpa82v9a36bg0/image_1d4puspcj1p8m1gh2f0gp297f497.png" alt="image_1d4puspcj1p8m1gh2f0gp297f497.png-69.2kB"></p>
<ul>
<li>所有的过程合并起来就是下图：</li>
</ul>
<p><img src="http://static.zybuluo.com/chuanfanyoudong/ok5ec4w07zgrzk4i0d25jwvj/image_1d4puuasenl81p5j15r15o71u57a4.png" alt="image_1d4puuasenl81p5j15r15o71u57a4.png-131.1kB"></p>
<h3 id="编码序列的位置信息"><a href="#编码序列的位置信息" class="headerlink" title="编码序列的位置信息"></a>编码序列的位置信息</h3><ul>
<li><p>上文所有的过程都没有用到位置信息，我们记录了位置向量和输入的向量结合，如下图：<br><img src="http://static.zybuluo.com/chuanfanyoudong/kiodb6kb4ow1r5p1du6vwu5q/image_1d4q0fd93gfhhfg1dicdqert2o.png" alt="image_1d4q0fd93gfhhfg1dicdqert2o.png-72.9kB"></p>
</li>
<li><p>就是两个向量对应位加和：<br><img src="http://static.zybuluo.com/chuanfanyoudong/wcp6ocl4vs5bwa287wdr5nse/image_1d4q0gs1tcp2sf6aai14nvdau35.png" alt="image_1d4q0gs1tcp2sf6aai14nvdau35.png-35.3kB"></p>
</li>
<li><p>下图是一个20个词的512维度的位置向量计算方法， 中间有断层，是因为维度的前半部分和后半部分使用了两个函数<br><img src="http://static.zybuluo.com/chuanfanyoudong/92zunmx5o3d5k6yqbj3v7ly2/image_1d4q0rh866gv1mdv5tfgop1ttf42.png" alt="image_1d4q0rh866gv1mdv5tfgop1ttf42.png-80.8kB"></p>
</li>
</ul>
<h3 id="残差信息"><a href="#残差信息" class="headerlink" title="残差信息"></a>残差信息</h3><p>每一个头（8个头中的一个）的self_attention都要经历一次normalization。<br><img src="http://static.zybuluo.com/chuanfanyoudong/r0e6jj7w5m4stfv3cwx8uyou/image_1d4q1378418k61crpo5k1tlnrda4v.png" alt="image_1d4q1378418k61crpo5k1tlnrda4v.png-75.6kB"></p>
<h3 id="两层的结构如下："><a href="#两层的结构如下：" class="headerlink" title="两层的结构如下："></a>两层的结构如下：</h3><p><img src="http://static.zybuluo.com/chuanfanyoudong/m6aezsoro4p99gzwuri48y64/image_1d4q155u21oma75n17o7hn84rg5c.png" alt="image_1d4q155u21oma75n17o7hn84rg5c.png-171.7kB"></p>
<h2 id="decoder部分"><a href="#decoder部分" class="headerlink" title="decoder部分"></a>decoder部分</h2><ul>
<li>解码部分会用到encoder阶段生成的key矩阵和value矩阵。一次一个的生成词。</li>
<li>解码部分的只能输入要翻译的词前面的所有的词，因为实际情况下，你不可能知道后面的词语，所以会有一个遮蔽矩阵。</li>
<li>encoder-decoder 矩阵的query矩阵使用的是decoder的query，而key矩阵和value矩阵使用的是encoder部分的矩阵。</li>
</ul>
<h2 id="最终的全连接与softmax"><a href="#最终的全连接与softmax" class="headerlink" title="最终的全连接与softmax"></a>最终的全连接与softmax</h2><ul>
<li>这个不多说了，看图</li>
<li><img src="http://static.zybuluo.com/chuanfanyoudong/xzg1b3zvat4jq5fuddtu9azg/image_1d4q1st4jbk4ic2bl84391jvj5p.png" alt="image_1d4q1st4jbk4ic2bl84391jvj5p.png-72.7kB"></li>
<li>简单说就是decoder的输出，会经过全连接生成1*词表大小的矩阵，然后softmax选出最大值。</li>
</ul>
<h2 id="训练过程的复盘"><a href="#训练过程的复盘" class="headerlink" title="训练过程的复盘"></a>训练过程的复盘</h2><h2 id="损失函数——loss-function"><a href="#损失函数——loss-function" class="headerlink" title="损失函数——loss function"></a>损失函数——loss function</h2><ul>
<li>交叉熵</li>
</ul>
<h3 id="预测的时候用到了-beam-search方法"><a href="#预测的时候用到了-beam-search方法" class="headerlink" title="预测的时候用到了 beam search方法"></a>预测的时候用到了 beam search方法</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/36029811?group_id=972420376412762112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36029811?group_id=972420376412762112</a></li>
<li>主要思想就是翻译当前字符的时候，考虑到了上一字符的结果过，每次维护N个最佳路线，最终输出。</li>
</ul>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。有问题需要讨论可以在github提issue https://github.com/chuanfanyoudong/chuanfanyoudong.github.io-/issues，也可以邮件至 jiang_zhenkang@163.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>


<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>Transformer解释</p>
    <p><span class="copy-title">文章字数:</span><span class="post-count">1.5k</span></p>
    <p><span class="copy-title">本文作者:</span><a  title="船帆有洞">船帆有洞</a></p>
    <p><span class="copy-title">发布时间:</span>2021-12-17, 00:00:00</p>
    <p><span class="copy-title">最后更新:</span>2022-03-17, 08:27:22</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/2021/12/17/transformer/" title="Transformer解释">http://blog.chuanfanyoudong.com/2021/12/17/transformer/</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>



    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: '50518d804b2e3f8e81e6',
            clientSecret: 'a5e777eada096638c8a7b94acee72ad58679c541',
            repo: 'chuanfanyoudong.github.io',
            owner: 'chuanfanyoudong',
            admin: ['chuanfanyoudong'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2019-2020 chuanfanyoudong</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#生活','#自然语言处理','#文本分类','#算法','#python','#hexo','#随笔',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: #fafafa;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.3;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>







</html>
